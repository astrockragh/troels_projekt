{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.981Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import HomeMade as hm\n",
    "from importlib import reload  \n",
    "hm=reload(hm)\n",
    "import seaborn as sb\n",
    "from iminuit import Minuit\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "import dill\n",
    "from AppStatFunctions import Chi2Regression,UnbinnedLH, BinnedLH, add_text_to_ax, nice_string_output\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from hep_ml.reweight import GBReweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.983Z"
    }
   },
   "outputs": [],
   "source": [
    "Nmax=2.4e6\n",
    "uncorrelated=['v0_chi2', 'v0_px1', 'v0_phi1', 'v0_py1', 'v0_py', 'v0_py2', 'v0_phi2', 'v0_px2', 'v0_px', 'cosTheta', 'a0xy', 'a0', 'v0_y', 'v0_x', 'v0_rxyErr', 'v0_rxy','v0_z', 'pv0_z', 'pv0_y', 'ntrk_pv0', 'pv0_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.986Z"
    }
   },
   "outputs": [],
   "source": [
    "ml1=['v0_chi2', 'v0_px1', 'v0_phi1', 'v0_py1', 'v0_py', 'v0_py2', 'v0_phi2', 'v0_px2', 'v0_px']\n",
    "ml2=['cosTheta', 'a0xy', 'a0', 'v0_y', 'v0_x', 'v0_rxyErr', 'v0_rxy','v0_z', 'pv0_z', 'pv0_y', 'ntrk_pv0', 'pv0_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.989Z"
    }
   },
   "outputs": [],
   "source": [
    "N = Nmax\n",
    "if N>Nmax:\n",
    "    N=Nmax\n",
    "    print('Maxed out')\n",
    "\n",
    "all_features = np.hstack((['v0_ks_mass'], uncorrelated))\n",
    "\n",
    "path = \"../../data/data15_13TeV.00267358.physics_MinBias.30062015_v0_per_0.root\"\n",
    "file = uproot.open(path)\n",
    "data = file['tree'].pandas.df(all_features, entrystop = N)\n",
    "\n",
    "path = \"../../data/mc15_13TeV.361203.Pythia8_A2_MSTW2008LO_ND_minbias.30062015_v0_per_0.root\"\n",
    "file = uproot.open(path)\n",
    "mc = file['tree'].pandas.df(np.hstack((all_features ,['trueKs'])), entrystop = N)\n",
    "\n",
    "data = data.loc[(data.v0_ks_mass > 400) & (data.v0_ks_mass < 600)]\n",
    "train_data = data.sample(frac=0.7)\n",
    "test_data = data[~data.index.isin(train_data.index)]\n",
    "\n",
    "mc = mc.loc[(mc.v0_ks_mass > 400) & (mc.v0_ks_mass < 600)]\n",
    "train_mc = mc.sample(frac=0.7)\n",
    "test_mc = mc[~mc.index.isin(train_mc.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.991Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from hep_ml.metrics_utils import ks_2samp_weighted\n",
    "\n",
    "hist_settings = {'bins': 100, 'density': True, 'alpha': 0.7}\n",
    "\n",
    "def draw_distributions(original, target, new_original_weights, plot=True, verbose=True):\n",
    "    s=[]\n",
    "    plt.figure(figsize=[20, 20])\n",
    "    for id, column in enumerate(original.columns, 1):\n",
    "        print(column)\n",
    "        xlim = np.percentile(np.hstack([target[column]]), [0.01, 99.99])\n",
    "        if plot:\n",
    "            plt.subplot(5, 5, id)\n",
    "            plt.hist(original[column], weights=new_original_weights, range=xlim, **hist_settings)\n",
    "            plt.hist(target[column], range=xlim, **hist_settings)\n",
    "            plt.title(column)\n",
    "        kstest=ks_2samp_weighted(original[column], target[column], \n",
    "                                         weights1=new_original_weights, weights2=np.ones(len(target), dtype=float))\n",
    "        if verbose:\n",
    "            print('KS over ', column, ' = ',kstest)\n",
    "        s.append(kstest)\n",
    "    return np.sum(s)/len(s), np.array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.994Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_distributions(original, target, new_original_weights):\n",
    "    s=[]\n",
    "    for id, column in enumerate(original.columns, 1):\n",
    "        s.append(ks_2samp_weighted(original[column], target[column], \n",
    "                                         weights1=new_original_weights, weights2=np.ones(len(target), dtype=float)))\n",
    "    return np.sum(s)/len(s), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.996Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_split(mcs, datas, split, paramlist, no_transform):\n",
    "    mc1, data1=mcs[paramlist], datas[paramlist]\n",
    "    testlen=int(len(mc)*(1-split))\n",
    "    mct, datat=RobustScaler().fit(mc1), RobustScaler().fit(mc1)\n",
    "    mc1, data1=mct.transform(mc1), datat.transform(data1)\n",
    "    mc1, data1=pd.DataFrame(mc1, columns=paramlist), pd.DataFrame(data1, columns=paramlist)\n",
    "    for no in no_transform:\n",
    "        mc1[no]=mcs[no].to_numpy()\n",
    "        data1[no]=datas[no].to_numpy()\n",
    "    true=mc.trueKs\n",
    "    return mc1[:testlen], mc1[testlen:], data1[:testlen], data1[testlen:], true[:testlen], true[testlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:14.998Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split(mc, data, 0.7, uncorrelated, ['v0_chi2', 'cosTheta', 'v0_ks_mass'])\n",
    "mcweights_train = np.ones(len(mc_train))\n",
    "mcweights_test = np.ones(len(mc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the scaled stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.002Z"
    }
   },
   "outputs": [],
   "source": [
    "s, sarray=draw_distributions(mc_test[uncorrelated], data_test[uncorrelated], mcweights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the non_scaled population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.005Z"
    }
   },
   "outputs": [],
   "source": [
    "sorig, sorigarray=draw_distributions(mc[uncorrelated], data[uncorrelated], np.ones(len(mc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.008Z"
    }
   },
   "outputs": [],
   "source": [
    "sorig/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.011Z"
    }
   },
   "outputs": [],
   "source": [
    "sorig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We gain a bit with the new scaled and centereed distributions, about 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.014Z"
    }
   },
   "outputs": [],
   "source": [
    "paramsure=['v0_ks_mass','v0_chi2', 'v0_px1', 'v0_phi1', 'v0_py1', 'v0_py', 'v0_py2', 'v0_phi2', 'v0_px2', 'v0_px', 'cosTheta', 'a0xy', 'v0_x', 'v0_rxyErr', 'v0_z' ]\n",
    "extra=[ 'a0xy', 'a0,' 'v0_x', 'v0_rxyErr', 'v0_z', 'pv0_z']\n",
    "extra=[ 'a0xy', 'v0_rxyErr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.017Z"
    }
   },
   "outputs": [],
   "source": [
    "features=paramsure\n",
    "slist=[]\n",
    "#trying to add ks mass to non scaled\n",
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split(mc, data, 0.7, features, ['v0_chi2', 'cosTheta', 'v0_ks_mass'])\n",
    "reweighter = GBReweighter(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=1000)\n",
    "reweighter.fit(mc_train[features], data_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.020Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_weights_test = reweighter.predict_weights(mc_test[features])\n",
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s, _ =draw_distributions(mc_test[features], data_test[features], gb_weights_test, verbose=0)\n",
    "slist.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.023Z"
    }
   },
   "outputs": [],
   "source": [
    "s, sorig/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 times better! Watch out for disturbance in mass though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.027Z"
    }
   },
   "outputs": [],
   "source": [
    "#NAMES: mc_test, mc_train, data_test, data_train, truetest, truetrain\n",
    "params=features[1:]\n",
    "import xgboost\n",
    "train_weights = reweighter.predict_weights(mc_train[paramsure])\n",
    "test_weights = reweighter.predict_weights(mc_test[paramsure])\n",
    "eval_s = [(mc_train[params], truetrain), (mc_test[params], truetest)]\n",
    "eval_weights=[train_weights, test_weights]\n",
    "model = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 1000)\n",
    "model.fit(mc_train[params], truetrain, sample_weight=train_weights, verbose=True,eval_set=eval_s, sample_weight_eval_set=eval_weights,\n",
    "          early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.030Z"
    }
   },
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# # load JS visualization code to notebook\n",
    "# shap.initjs()\n",
    "\n",
    "# # explain the model's predictions using SHAP\n",
    "# # (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(mc_train[params])\n",
    "\n",
    "# # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "# shap.summary_plot(shap_values, mc_train[params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.032Z"
    }
   },
   "outputs": [],
   "source": [
    "pxg=model.predict_proba(data_train[params])[:,1]\n",
    "plt.hist(pxg, bins=100);\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.034Z"
    }
   },
   "outputs": [],
   "source": [
    "true=pxg>0.7\n",
    "plt.hist(data_train.v0_ks_mass[true], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.037Z"
    }
   },
   "outputs": [],
   "source": [
    "#just for fun\n",
    "pxgt=model.predict_proba(data_test[params])[:,1]\n",
    "truetest=pxgt>0.7\n",
    "plt.hist(data_test.v0_ks_mass[truetest], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.040Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_s = [(data_train[params], true), (data_test[params], truetest)]\n",
    "# tsts.append(X_train)\n",
    "modeldata = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeldata.fit(data_train[params], true,verbose=True,eval_set=eval_s,early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.042Z"
    }
   },
   "outputs": [],
   "source": [
    "p_final=modeldata.predict_proba(data_test[params])[:,0]\n",
    "true_final=p_final>0.75\n",
    "plt.hist(data_test.v0_ks_mass[true_final], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.045Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_test.v0_ks_mass[~true_final], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.048Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "hm.roc_curve_data(data_test.v0_ks_mass, p_final, Npoints = 100, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = True, plimit = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.052Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split(mc, data, 0.7, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])\n",
    "eval_s = [(mc_train[uncorrelated], truetrain), (mc_test[uncorrelated], truetest)]\n",
    "model = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "model.fit(mc_train[uncorrelated], truetrain, verbose=True,eval_set=eval_s,\n",
    "          early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.055Z"
    }
   },
   "outputs": [],
   "source": [
    "pxg=model.predict_proba(data_train[uncorrelated])[:,1]\n",
    "plt.hist(pxg, bins=100);\n",
    "# plt.yscale('log')\n",
    "true=pxg>0.7\n",
    "plt.hist(data_train.v0_ks_mass[true], bins=100);\n",
    "#just for fun\n",
    "#just for fun\n",
    "pxgt=model.predict_proba(data_test[uncorrelated])[:,1]\n",
    "true_test=pxgt>0.7\n",
    "plt.hist(data_test.v0_ks_mass[true_test], bins=100);\n",
    "\n",
    "\n",
    "eval_s = [(data_train[uncorrelated], true), (data_test[uncorrelated], true_test)]\n",
    "modeldata = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeldata.fit(data_train[uncorrelated], true,verbose=True,eval_set=eval_s,early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.058Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "hm.roc_curve_data(data_test.v0_ks_mass, p_final, Npoints = 100, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = True, plimit = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.060Z"
    }
   },
   "outputs": [],
   "source": [
    "p_final=modeldata.predict_proba(data_test[uncorrelated])[:,0]\n",
    "true_final=p_final>0.8\n",
    "plt.hist(data_test.v0_ks_mass[true_final], bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing straight training in MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.063Z"
    }
   },
   "outputs": [],
   "source": [
    "train_weights = reweighter.predict_weights(mc_train[paramsure])\n",
    "test_weights = reweighter.predict_weights(mc_test[paramsure])\n",
    "eval_s = [(mc_train[params], truetrain), (mc_test[params], truetest)]\n",
    "eval_weights=[train_weights, test_weights]\n",
    "modelw = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelw.fit(mc_train[params], truetrain, sample_weight=train_weights, verbose=True,eval_set=eval_s, sample_weight_eval_set=eval_weights,\n",
    "          early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.066Z"
    }
   },
   "outputs": [],
   "source": [
    "pxgw=modelw.predict_proba(data_train[params])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.068Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "hm.roc_curve_data(data_train.v0_ks_mass, pxgw, Npoints = 100, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.071Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split(mc, data, 0.7, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])\n",
    "eval_s = [(mc_train[uncorrelated], truetrain), (mc_test[uncorrelated], truetest)]\n",
    "modelnw = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelnw.fit(mc_train[uncorrelated], truetrain, eval_set=eval_s, verbose=True, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.074Z"
    }
   },
   "outputs": [],
   "source": [
    "pxgnw=modelnw.predict_proba(data_train[uncorrelated])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.076Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, pxgnw, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.079Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1.set(xlabel='FPR', ylabel='TPR', xlim=(-0.05,1.05), ylim=(-0.05,1.05), title=f'Estimated ROC curve, AUC $\\approx$ {1+a}')\n",
    "plt.savefig('roccurvenoreweigh.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.081Z"
    }
   },
   "outputs": [],
   "source": [
    "uncorrelated=params\n",
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split(mc, data, 0.7, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])\n",
    "eval_s = [(pd.concat((data_train[uncorrelated], mc_train[uncorrelated])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train))))), \n",
    "          (pd.concat((data_test[uncorrelated], mc_test[uncorrelated])),  np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))))]\n",
    "modelnw = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelnw.fit(pd.concat((data_train[uncorrelated], mc_train[uncorrelated])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train)))),\n",
    "            eval_set=eval_s, verbose=True, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.084Z"
    }
   },
   "outputs": [],
   "source": [
    "pnw=modelnw.predict_proba(pd.concat((data_test[uncorrelated], mc_test[uncorrelated])))[:,1]\n",
    "true=pnw>0.7\n",
    "plt.hist(pnw, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.089Z"
    }
   },
   "outputs": [],
   "source": [
    "train_weights = reweighter.predict_weights(mc_train[paramsure])\n",
    "test_weights = reweighter.predict_weights(mc_test[paramsure])\n",
    "eval_weights=[np.hstack((np.ones(len(data_train)), train_weights)), np.hstack((np.ones(len(data_test)), test_weights))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.093Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split(mc, data, 0.7, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])\n",
    "eval_s = [(pd.concat((data_train[params], mc_train[params])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train))))), \n",
    "          (pd.concat((data_test[params], mc_test[params])),  np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))))]\n",
    "modelw = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelw.fit(pd.concat((data_train[params], mc_train[params])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train)))), \n",
    "            sample_weight=eval_weights[0], eval_set=eval_s, sample_weight_eval_set=eval_weights,\n",
    "            verbose=True, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.095Z"
    }
   },
   "outputs": [],
   "source": [
    "pw=modelw.predict_proba(pd.concat((data_test[params], mc_test[params])))[:,1]\n",
    "true=pw>0.8\n",
    "plt.hist(pw, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.098Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_true=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))),\n",
    "                                y_score=pw)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tpr,fpr)\n",
    "ax.plot([0,1],[0,1],c='grey',linestyle='--')\n",
    "ax.set_title(f'ROC curve, AUC: {1-roc_auc_score(y_true=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))),y_score=pw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.101Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "explainer = shap.TreeExplainer(modelw)\n",
    "shap_values = explainer.shap_values(pd.concat((data_test[params], mc_test[params])))\n",
    "\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.summary_plot(shap_values, pd.concat((data_test[params], mc_test[params])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.104Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_true=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))),\n",
    "                                y_score=pnw)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tpr,fpr)\n",
    "ax.plot([0,1],[0,1],c='grey',linestyle='--')\n",
    "ax.set_title(f'ROC curve, AUC: {1-roc_auc_score(y_true=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))),y_score=pnw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.107Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "explainer = shap.TreeExplainer(modelnw)\n",
    "shap_values = explainer.shap_values(pd.concat((data_test[params], mc_test[params])))\n",
    "\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.summary_plot(shap_values, pd.concat((data_test[params], mc_test[params])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.111Z"
    }
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a different scaling method: MinMaxScaling (with robustness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.116Z"
    }
   },
   "outputs": [],
   "source": [
    "so, solist=draw_distributions(mc[all_features], data[all_features], np.ones(len(mc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.120Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def scale_split2(mcs, datas, split, quantile, paramlist, no_transform):\n",
    "    mc1, data1=mcs[paramlist], datas[paramlist]\n",
    "    testlen=int(len(mc)*(1-split))\n",
    "    \n",
    "    for param in paramlist:\n",
    "        if param not in no_transform:\n",
    "            print(param+' is being transformed' )\n",
    "            q_mc, q_data = (mcs.quantile(1-quantile)[param], mcs.quantile(quantile)[param]), (datas.quantile(1-quantile)[param], datas.quantile(quantile)[param])\n",
    "            mcq, dataq = mcs.loc[(mcs[param] > q_mc[0]) & (mcs[param] < q_mc[1])], datas.loc[(datas[param] > q_data[0]) & (datas[param] < q_data[1])]\n",
    "            mcscaler, datascaler=MinMaxScaler().fit( (mcq[param]).to_numpy().reshape(-1, 1) ), MinMaxScaler().fit( (dataq[param]).to_numpy().reshape(-1, 1))  \n",
    "            mcscaled, datascaled= mcscaler.transform( (mcs[param]).to_numpy().reshape(-1, 1) ), datascaler.transform( (datas[param]).to_numpy().reshape(-1, 1) ) \n",
    "            mc1[param], data1[param]=mcscaled, datascaled\n",
    "    true=mc.trueKs\n",
    "    return mc1[:testlen], mc1[testlen:], data1[:testlen], data1[testlen:], true[:testlen], true[testlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.137Z"
    }
   },
   "outputs": [],
   "source": [
    "uncorrelated=['v0_chi2', 'v0_px1', 'v0_phi1', 'v0_py1', 'v0_py', 'v0_py2', 'v0_phi2','v0_px2', 'v0_px', \n",
    "              'cosTheta', 'a0xy', 'a0', 'v0_y', 'v0_x', 'v0_rxyErr', 'v0_rxy','v0_z', 'pv0_z', 'pv0_y', 'ntrk_pv0', 'pv0_x']\n",
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split2(mc, data, \n",
    "                    0.7, 0.78, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.156Z"
    }
   },
   "outputs": [],
   "source": [
    "ses=[]\n",
    "for i in range(70,80):\n",
    "    split=i/100\n",
    "    mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split2(mc, data, \n",
    "                    0.7, split, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])\n",
    "    s1, s1list=compare_distributions(mc_train, data_train, np.ones(len(mc_train)))\n",
    "    ses.append(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.160Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(70,80),ses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.164Z"
    }
   },
   "outputs": [],
   "source": [
    "features=np.hstack((['v0_ks_mass'], uncorrelated))\n",
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split2(mc, data, \n",
    "                    0.78, split, features, ['v0_chi2','v0_ks_mass', 'cosTheta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.167Z"
    }
   },
   "outputs": [],
   "source": [
    "sn, snlist=draw_distributions(mc_test, data_test, np.ones(len(mc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.170Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(solist)-np.array(snlist))\n",
    "plt.hlines(0, 0,22, linestyle='dashed')\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.173Z"
    }
   },
   "outputs": [],
   "source": [
    "so/sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's do ml1/ml2 and ml1+ml2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.176Z"
    }
   },
   "outputs": [],
   "source": [
    "print(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.179Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "reweighter12 = GBReweighter(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=1000)\n",
    "reweighter12.fit(mc_train[all_features], data_train[all_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.182Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_weights_test = reweighter12.predict_weights(mc_test[features])\n",
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s12, _ =draw_distributions(mc_test[features], data_test[features], gb_weights_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.184Z"
    }
   },
   "outputs": [],
   "source": [
    "#need to get mass in on both\n",
    "\n",
    "ML1, ML2=np.hstack((['v0_ks_mass'], ml1)), np.hstack((['v0_ks_mass'], ml2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.188Z"
    }
   },
   "outputs": [],
   "source": [
    "reweighter1 = GBReweighter(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=1000)\n",
    "reweighter1.fit(mc_train[ML1], data_train[ML1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.191Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_weights1 = reweighter1.predict_weights(mc_test[ML1])\n",
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s1, _ =draw_distributions(mc_test[ML1], data_test[ML1], gb_weights1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.194Z"
    }
   },
   "outputs": [],
   "source": [
    "reweighter2 = GBReweighter(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=1000)\n",
    "reweighter2.fit(mc_train[ML2], data_train[ML2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.197Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_weights2 = reweighter2.predict_weights(mc_test[ML2])\n",
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s2, _ =draw_distributions(mc_test[ML2], data_test[ML2], gb_weights2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so it's ml2 that's fucking shit up. Let's find out where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.203Z"
    }
   },
   "outputs": [],
   "source": [
    "slist=[]\n",
    "check=['v0_ks_mass','cosTheta','a0xy','a0','v0_y','v0_x','v0_rxyErr','v0_rxy','v0_z']\n",
    "extra=['pv0_z','pv0_y','ntrk_pv0','pv0_x']\n",
    "for e in extra:\n",
    "    tot=np.hstack((check, e))\n",
    "    rw = GBReweighter(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=1000)\n",
    "    rw.fit(mc_train[tot], data_train[tot])\n",
    "    weightstest = rw.predict_weights(mc_test[tot])\n",
    "    # validate reweighting rule on the test part comparing 1d projections\n",
    "    ss, _ =draw_distributions(mc_test[tot], data_test[tot], weightstest, verbose=0, plot=0)\n",
    "    slist.append(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.207Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(extra, slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can probably keep ntrk_pv0 and pv0_x but it turns out that keeping both is bad\n",
    "\n",
    "Let's also try removing a0 since most of that information is in a0xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.210Z"
    }
   },
   "outputs": [],
   "source": [
    "ML2=['v0_ks_mass','cosTheta','a0','v0_y','v0_x','v0_rxyErr','v0_rxy','v0_z','ntrk_pv0']\n",
    "obsolote=[ 'pv0_x','pv0_z','pv0_x', 'a0xy']\n",
    "reweighter2 = GBReweighter(n_estimators=100, learning_rate=0.1, max_depth=4, min_samples_leaf=1000)\n",
    "reweighter2.fit(mc_train[ML2], data_train[ML2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.213Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_weights2 = reweighter2.predict_weights(mc_test[ML2])\n",
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s2, _ =draw_distributions(mc_test[ML2], data_test[ML2], gb_weights2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:34:09.931549Z",
     "start_time": "2020-10-26T20:34:09.926562Z"
    }
   },
   "source": [
    "Throw out a0xy and keep ntrk_pv0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the whole thing while still drawing the obsolete parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.218Z"
    }
   },
   "outputs": [],
   "source": [
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s2, _ =draw_distributions(mc_test[ml2], data_test[ml2], gb_weights2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the reweighter for the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.222Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features=['v0_ks_mass', 'v0_chi2', 'v0_px1', 'v0_phi1', 'v0_py1', 'v0_py',\n",
    "       'v0_py2', 'v0_phi2', 'v0_px2', 'v0_px', 'cosTheta', 'a0',\n",
    "       'v0_y', 'v0_x', 'v0_rxyErr', 'v0_rxy', 'v0_z', 'ntrk_pv0']\n",
    "reweighter12 = GBReweighter(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=1000)\n",
    "reweighter12.fit(mc_train[train_features], data_train[train_features])\n",
    "\n",
    "gb_weights_test = reweighter12.predict_weights(mc_test[train_features])\n",
    "# validate reweighting rule on the test part comparing 1d projections\n",
    "s12, _ =draw_distributions(mc_test[train_features], data_test[train_features], gb_weights_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.225Z"
    }
   },
   "outputs": [],
   "source": [
    "s12, _ =draw_distributions(mc_test[all_features], data_test[all_features], gb_weights_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.236Z"
    }
   },
   "outputs": [],
   "source": [
    "s1, s2, s12, so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing whether xgboost can see the difference for the three scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check ML1\n",
    "- can we make a classifier that can tell the difference?\n",
    "- how does prediction for this do if we;\n",
    "\n",
    "1: Do not reweigh MC and use it in data\n",
    "\n",
    "2: Reweigh MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.241Z"
    }
   },
   "outputs": [],
   "source": [
    "train_weights1 = reweighter1.predict_weights(mc_train[ML1])\n",
    "test_weights1 = reweighter1.predict_weights(mc_test[ML1])\n",
    "eval_weights1=[np.hstack((np.ones(len(data_train)), train_weights1)), np.hstack((np.ones(len(data_test)), test_weights1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.244Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "eval_s = [(pd.concat((data_train[ml1], mc_train[ml1])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train))))), \n",
    "          (pd.concat((data_test[ml1], mc_test[ml1])),  np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))))]\n",
    "modelw1 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelw1.fit(pd.concat((data_train[ml1], mc_train[ml1])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train)))), \n",
    "            sample_weight=eval_weights1[0], eval_set=eval_s, sample_weight_eval_set=eval_weights1,\n",
    "            verbose=True, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.247Z"
    }
   },
   "outputs": [],
   "source": [
    "p1=modelw1.predict_proba(pd.concat((data_test[ml1], mc_test[ml1])))[:,0]\n",
    "plt.hist(p1, bins=100)\n",
    "truetest=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.250Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_true=truetest,\n",
    "                                y_score=p1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tpr,fpr)\n",
    "ax.plot([0,1],[0,1],c='grey',linestyle='--')\n",
    "ax.set_title(f'ROC curve for ML1, reweighed, AUC: {1-roc_auc_score(y_true=truetest,y_score=p1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.255Z"
    }
   },
   "outputs": [],
   "source": [
    "features=np.hstack((['v0_ks_mass'], uncorrelated))\n",
    "uncorrelated=['v0_chi2', 'v0_px1', 'v0_phi1', 'v0_py1', 'v0_py', 'v0_py2', 'v0_phi2','v0_px2', 'v0_px', \n",
    "              'cosTheta', 'a0xy', 'a0', 'v0_y', 'v0_x', 'v0_rxyErr', 'v0_rxy','v0_z', 'pv0_z', 'pv0_y', 'ntrk_pv0', 'pv0_x']\n",
    "mc_test, mc_train, data_test, data_train, truetest, truetrain=scale_split2(mc, data, \n",
    "                    0.7, 0.78, np.hstack((uncorrelated, ['v0_ks_mass'])), ['v0_chi2','v0_ks_mass', 'cosTheta'])\n",
    "eval_s1 = [(mc_train[ml1], truetrain), (mc_test[ml1], truetest)]\n",
    "modeld1 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeld1.fit(mc_train[ml1], truetrain, verbose=True,eval_set=eval_s1, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.257Z"
    }
   },
   "outputs": [],
   "source": [
    "p1_d=modeld1.predict_proba((data_train[ml1]))[:,1]\n",
    "true1_d=p1_d>0.5\n",
    "plt.hist(data_train.v0_ks_mass[true1_d], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.259Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, 1-p1_d, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)\n",
    "1+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.262Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_weights1=[train_weights1, test_weights1]\n",
    "eval_s1 = [(mc_train[ml1], truetrain), (mc_test[ml1], truetest)]\n",
    "modeldw1 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeldw1.fit(mc_train[ml1], truetrain, sample_weight=train_weights1, verbose=True,eval_set=eval_s1, \n",
    "             sample_weight_eval_set=eval_weights1,early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.264Z"
    }
   },
   "outputs": [],
   "source": [
    "p1_dw=modeldw1.predict_proba((data_train[ml1]))[:,1]\n",
    "true1_dw=p1_dw>0.5\n",
    "plt.hist(p1_dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.266Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_train.v0_ks_mass[true1_dw], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.268Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, 1-p1_dw, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)\n",
    "1+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check ML2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.270Z"
    }
   },
   "outputs": [],
   "source": [
    "train_weights2 = reweighter2.predict_weights(mc_train[ML2])\n",
    "test_weights2 = reweighter2.predict_weights(mc_test[ML2])\n",
    "eval_weights2=[np.hstack((np.ones(len(data_train)), train_weights2)), np.hstack((np.ones(len(data_test)), test_weights2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.273Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_s2 = [(pd.concat((data_train[ml2], mc_train[ml2])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train))))), \n",
    "          (pd.concat((data_test[ml2], mc_test[ml2])),  np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))))]\n",
    "modelw2 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelw2.fit(pd.concat((data_train[ml2], mc_train[ml2])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train)))), \n",
    "            sample_weight=eval_weights1[0], eval_set=eval_s2, sample_weight_eval_set=eval_weights2,\n",
    "            verbose=True, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.275Z"
    }
   },
   "outputs": [],
   "source": [
    "p2=modelw2.predict_proba(pd.concat((data_test[ml2], mc_test[ml2])))[:,0]\n",
    "plt.hist(p2, bins=100)\n",
    "true_test=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.277Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true=true_test,\n",
    "                                y_score=p2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tpr,fpr)\n",
    "ax.plot([0,1],[0,1],c='grey',linestyle='--')\n",
    "ax.set_title(f'ROC curve for ML2, reweighed, AUC: {1-roc_auc_score(y_true=true_test,y_score=p2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.279Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_s2 = [(mc_train[ml2], truetrain), (mc_test[ml2], truetest)]\n",
    "modeld2 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeld2.fit(mc_train[ml2], truetrain, verbose=True,eval_set=eval_s2, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.281Z"
    }
   },
   "outputs": [],
   "source": [
    "p2_d=modeld2.predict_proba((data_train[ml2]))[:,1]\n",
    "true2_d=p2_d>0.7\n",
    "plt.hist(p2_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.283Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_train.v0_ks_mass[true2_d], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.285Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, 1-p2_d, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)\n",
    "1+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.288Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_weights2=[train_weights2, test_weights2]\n",
    "eval_s2 = [(mc_train[ml2], truetrain), (mc_test[ml2], truetest)]\n",
    "modeldw2 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeldw2.fit(mc_train[ml2], truetrain, sample_weight=train_weights2, verbose=True,eval_set=eval_s2, \n",
    "             sample_weight_eval_set=eval_weights2,early_stopping_rounds=50,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.290Z"
    }
   },
   "outputs": [],
   "source": [
    "p2_dw=modeldw2.predict_proba((data_train[ml2]))[:,1]\n",
    "true2_dw=p2_dw>0.62\n",
    "plt.hist(p2_dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.292Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_train.v0_ks_mass[true2_dw], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.294Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, 1-p2_dw, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)\n",
    "1+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is inconclusive as towards whether the reweighted instance is better or not\n",
    "\n",
    "Let's go for ml1+ml2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.296Z"
    }
   },
   "outputs": [],
   "source": [
    "train_weights12 = reweighter12.predict_weights(mc_train[train_features])\n",
    "test_weights12 = reweighter12.predict_weights(mc_test[train_features])\n",
    "eval_weights12=[np.hstack((np.ones(len(data_train)), train_weights12)), np.hstack((np.ones(len(data_test)), test_weights12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.298Z"
    }
   },
   "outputs": [],
   "source": [
    "ml12=uncorrelated\n",
    "eval_s12 = [(pd.concat((data_train[ml12], mc_train[ml12])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train))))), \n",
    "          (pd.concat((data_test[ml12], mc_test[ml12])),  np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test)))))]\n",
    "modelw12 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modelw12.fit(pd.concat((data_train[ml12], mc_train[ml12])), np.hstack((np.ones(len(data_train)), np.zeros(len(mc_train)))), \n",
    "            sample_weight=eval_weights12[0], eval_set=eval_s12, sample_weight_eval_set=eval_weights12,\n",
    "            verbose=True, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.300Z"
    }
   },
   "outputs": [],
   "source": [
    "p12=modelw12.predict_proba(pd.concat((data_test[ml12], mc_test[ml12])))[:,0]\n",
    "plt.hist(p12, bins=100)\n",
    "true_test=np.hstack((np.ones(len(data_test)), np.zeros(len(mc_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.303Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true=true_test,\n",
    "                                y_score=p12)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tpr,fpr)\n",
    "ax.plot([0,1],[0,1],c='grey',linestyle='--')\n",
    "ax.set_title(f'ROC curve for ML1+ML2, reweighed, AUC: {1-roc_auc_score(y_true=true_test,y_score=p12)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.305Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_s12 = [(mc_train[ml12], truetrain), (mc_test[ml12], truetest)]\n",
    "modeld12 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeld12.fit(mc_train[ml12], truetrain, verbose=True,eval_set=eval_s12, early_stopping_rounds=30,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.307Z"
    }
   },
   "outputs": [],
   "source": [
    "p12_d=modeld12.predict_proba((data_train[ml12]))[:,1]\n",
    "true12_d=p12_d>0.75\n",
    "plt.hist(p12_d, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.309Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_train.v0_ks_mass[true12_d], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.311Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, 1-p12_d, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)\n",
    "1+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.313Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_weights12=[train_weights12, test_weights12]\n",
    "eval_s12 = [(mc_train[ml12], truetrain), (mc_test[ml12], truetest)]\n",
    "modeldw12 = xgboost.XGBClassifier(learning_rate = 0.02,n_estimators = 200)\n",
    "modeldw12.fit(mc_train[ml12], truetrain, sample_weight=train_weights12, verbose=True,eval_set=eval_s12, \n",
    "             sample_weight_eval_set=eval_weights12,early_stopping_rounds=50,eval_metric =\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.315Z"
    }
   },
   "outputs": [],
   "source": [
    "p12_dw=modeldw12.predict_proba((data_train[ml12]))[:,1]\n",
    "true12_dw=p12_dw>0.75\n",
    "plt.hist(p12_dw, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.317Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_train.v0_ks_mass[true12_dw], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T22:17:15.320Z"
    }
   },
   "outputs": [],
   "source": [
    "fig1, ax1=plt.subplots(figsize=(10,8))\n",
    "a,b=hm.roc_curve_data(data_train.v0_ks_mass, 1-p12_dw, Npoints = 50, bins = 100, range = (400, 600), ax_roc = ax1 ,\\\n",
    "             verbose = False, plimit = 0.9)\n",
    "1+a"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
